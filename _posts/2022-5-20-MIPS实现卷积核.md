---
layout:     post
title:      MIPS汇编语言实现卷积核
subtitle:   计算机组成原理
date:       2022/5/20
author:     Birdie
header-img: img/post_header.jpg
catalog: true
tags:
    - 计算机组成原理
    - MIPS
	- 汇编语言
---

### 一、实验目的

1. 学习 MIPS汇编语言，结合课上所学，熟练掌握相关MIPS汇编知识。 
2. 通过阅读参考文献，理解神经网络推理的过程。 
3. 阅读daBNN及其源代码，结合其他相关神经网络论文，了解如何实现神经网络卷积层的计算，并学习对其进行优化的思想，包括减少内存访问、重复利用寄存器等操作。
4. 了解二值神经网络与普通卷积神经网络在卷积层计算上的差别，并分析其带来的好处。

 

### 二、实验设备

1. ThinkPad E575 (操作系统：windows10)
2. Mars 4.5

 

### 三、实验内容

#### 3.1 普通整数卷积计算算子

使用 MIPS 汇编和 MIPS 仿真器，设计并实现一个普通整数卷积计算算子，要求有完整的输入输出，输入为 7\*7\*1 格式的张量，对应的卷积核一个，尺寸为 3\*3\*1，步长为 1，输出为经过卷积计算后的对应的 5\*5\*1 张量，要求计算结果正确。参考卷积操作图：

![1607226342(1)]({{site.url}}/img/2022-5-20-MIPS实现卷积核/clip_image004-16530486140462.gif)

#### 3.2 二值卷积计算算子

设计并实现一个二值卷积计算算子，要求有完整的输入输出，输入为 7\*7\*16bit 格式的张量，对应的卷积核一个，尺寸为 3\*3\*16bit，输出为经过卷积计算后的对应的 5\*5\*1 的张量，要求计算结果正确。

#### 3.3 偏置项、BN 层整合

在2的基础上，将卷积层的偏置项、BN 层整合到同一层内。

#### 3.4 寄存器复用优化

在3的基础上，对二值卷积计算算子进行寄存器复用优化。

 

### 四、实验原理

#### 4.1 卷积神经网络

##### 4.1.1 卷积神经网络的结构

第一层，输入层。输入层是一个n\*m\*h的矩阵，矩阵中的每个元素代表一个像素值。

第二层，隐含层。隐含层通常包括卷积层、池化层和全连接层。其中，卷积层的功能是对输入数据进行特征提取，其内部包含多个卷积核，组成卷积核的每个元素都对应一个权重系数和一个偏差量。直观上理解为，通过卷积核，对输入层中的每一个像素做线性运算。下图展示为卷积层的运算规则，其中input为输入层，kernel为卷积核（该卷积核中仅包含权重系数），输入层的深度和卷积核的深度一致。

<img src="{{site.url}}/img/2022-5-20-MIPS实现卷积核/clip_image006-16530486140463.gif" alt="1607257518(1)" style="zoom:50%;" />

将卷积核看作一个滑动的窗口，从输入层（即图像）的左上角开始滑动。上图中，卷积核可以覆盖2\*2的区域。现在，以卷积核所处在的第一个位置为例，即图像的左上角。此时，卷积核中的值会与图像中的原始像素值做点乘运算，得到一个2\*2的乘积矩阵，将矩阵中所有元素的值相加，即可得到第一个运算结果，即图中的aw+bx+ey+fz，为图像在该位置卷积运算后的结果。在输入内容上的每一位置重复该过程（下一步将是将卷积核右移 1 单元，接着再右移 1 单元，以此类推）。图像上的每一个特定位置都会产生一个数字，卷积核滑过所有位置后将得到一个2\*3的矩阵。该矩阵即是卷积层一次运算后的结果。

数学表达式为：

<img src="{{site.url}}/img/2022-5-20-MIPS实现卷积核/clip_image008-16530486140464.gif" alt="img" style="zoom:50%;" />

相比卷积层的复杂，池化层则要简单的多，池化就是对输入张量的各个子矩阵进行压缩。假如是2\*2的池化，那么就将子矩阵的每2\*2个元素变成1个元素，如果是3\*3的池化，那么就将子矩阵的每3\*3个元素变成1个元素，这样输入矩阵的维度就变小了。要想将输入子矩阵的每n\*n个元素变成一个元素，那么需要一个池化标准。常见的池化标准有2个，MAX或者是Average。即取对应区域的最大值或者平均值作为池化后的元素值。

由于池化层和全连接层在本次实验中不涉及，本报告中不过多赘述。

 

第三层是输出层。对于图像分类问题，输出层使用逻辑函数或归一化指数函数输出分类标签。

 

##### 4.1.2 向前推理引擎

输入层前向传播到卷积层，即将输入的图像导入卷积层。在上面已经讨论过卷积层的运算规则，此部分不再重复叙述。

这里需要定义的CNN模型参数是：

a. 一般卷积核不止一个，比如有k个，那么我们这一层卷积层的对应的输出的三维张量最后一维就为k。

b. 卷积核中每个子矩阵的的大小，一般我们都用子矩阵为方阵的卷积核，比如F\*F的子矩阵。

c. 填充(P)，卷积的时候，为了可以更好的识别边缘，一般都会在输入矩阵在周围加上若干圈的0再进行卷积，加多少圈则填充(P)为多少。

d. 步幅(S)，即在卷积过程中每次移动的像素距离大小。

在本题中，为了简化模型，k=1，P=1，S=1，卷积层数为1。

 

#### 4.2 二值卷积神经网络

分析普通卷积计算算子的时间，操作中，时间花费最大的两个指令，分别是mul（乘法）和lw（从内存中加载数值）。

由于MIPS架构中乘法器需要多次调用加法器，需要多个周期的时间，因此乘法器的时间开销比较高。而众所周知，位运算的运算时间比较短。因此，现在考虑将点乘运算中的乘法用位运算替换，二值卷积计算算子的出发点基于此。

##### 4.2.1 二值卷积神经网络概述

二值卷积神经网络是普通卷积神经网络的加速版本，在普通卷积神经网络的基础上，将输入的像素矩阵二值化。一般来说，一个像素值的区间范围是[0,255]。将像素值通过某种方式，压缩成1或者-1。在这个过程中，精度会发生损失，从原来可以表示多种特征下降为仅可以表示一种特征，但带来的收益是二值化的计算速度要远大于普通整数的计算，以及内存花销的降低。

在本部分中，二值化操作、损失函数的补偿以及梯度传播训练均不涉及，仅叙述卷积计算部分的过程。

##### 4.2.2 二值卷积计算算子

先将矩阵中的-1变成0，使得矩阵中的元素为二进制的值，便于位运算操作。

在二值神经网络中，乘法运算可以被xor（异或）和popcount（计数）操作取代。给出计算方法：

<img src="{{site.url}}/img/2022-5-20-MIPS实现卷积核/clip_image010-16530486140465.gif" alt="img" style="zoom:50%;" />

向量A和向量B分别是输入的张量矩阵和卷积核矩阵，Len是向量的长度。下图为验证计算方法的正确性：

<img src="{{site.url}}/img/2022-5-20-MIPS实现卷积核/clip_image012-16530486140466.gif" alt="1607311219(1)" style="zoom:50%;" />

 

#### 4.3 偏置项、BN层整合

在上述卷积层的操作中，我们忽略了偏置项和BN层的操作。上文提到，卷积层包含两个系数，一个是权重，即上述操作中所作的点乘运算；另一个是偏置项，即对计算出来的矩阵进行位移操作。

假设$x_1$为经过卷积层权值计算后的矩阵，$x_2$为经过偏置项计算后的矩阵，则有：

$$
x_2=x_1+b
$$

经过完整卷积层计算后的矩阵，若要作为输入图像导入下一个卷积层进行运算，需要进行归一化操作。这一步在BN层中完成，计算公式为：

<img src="{{site.url}}/img/2022-5-20-MIPS实现卷积核/clip_image020-165304861404610.gif" alt="img" style="zoom:50%;" />

$x_3$为经过归一化操作后得到的矩阵，$\mu$、$\sigma$分别为$x_2$的均值和标准差，$\gamma$、$\beta$为训练参数。

定义：

<img src="{{site.url}}/img/2022-5-20-MIPS实现卷积核/clip_image034-165304861404717.gif" alt="img" style="zoom:50%;" />

那么对$x_1$经过偏置项和BN层操作后，得到的$x_4$为：

<img src="{{site.url}}/img/2022-5-20-MIPS实现卷积核/clip_image040-165304861404720.gif" alt="1607338504(1)" style="zoom:50%;" />

#### 4.4 寄存器复用优化

##### 4.4.1 寄存器复用原理

在上文已经提到，在卷积运算中，时间花销最大的两个操作分别是mul（乘法）以及load（从内存中加载数值）。mul已经通过二值化的神经网络用位运算替代了，那么现在考虑降低load运算的时间。

考虑一次卷积计算，假设卷积核的大小为3\*3。在一个滑动窗口的过程中，从输入张量中提取一个3\*3的矩阵，与卷积核做点乘运算。该状态的下一个状态，为3\*3的矩阵向右平移一个单位。如下图所示：

<img src="{{site.url}}/img/2022-5-20-MIPS实现卷积核/clip_image042-165304861404721.gif" alt="1607359825(1)" style="zoom:50%;" />

可以发现，平移后，绿色部分的6个元素是和前一个状态相同的6个元素。那么此时，新一轮的运算可以不从内存中重新加载这6个元素，只需要加载新出现的三个元素。新一次的运算可以节省<img src="{{site.url}}/img/2022-5-20-MIPS实现卷积核/clip_image044-165304861404722.gif" alt="img" style="zoom:50%;" />的load时间。该优化称为寄存器复用优化。

由于该过程需要的寄存器数量过多，而mips的寄存器只有32个，在此使用了联合寄存器（即浮点数寄存器）存储卷积核。浮点数运算指令：

```
l.s $f1,100000($t2)

Load floating point Single precision : Set $f1 to 32-bit value at effective memory word address
```

即从内存中装载浮点数进入联合寄存器。

 
```
ceil.w.s $f0,$f1

Ceiling single precision to word : Set $f0 to 32-bit integer ceiling of single-precision float in $f1
```

即将浮点数向上取整。

 
```
floor.w.s $f0,$f1

Floor single precision to word : Set $f0 to 32-bit integer floor of single-precision float in $f1
```

即将浮点数向下取整。

 
```
mfc1 $t1,$f1

Move from Coprocessor 1 (FPU) : Set $t1 to value in Coprocessor 1 register $f1
```

将联合寄存器中的整数移动至普通寄存器。

特别注意的是，浮点数和整数在二进制中的保存方式不一样，使用该指令时需要联合寄存器中的数值为整数形式存在。

另外，将指令中的“.s”替换为“.d”，即可操作double类型的浮点数，“.s”指令用于操作float类型的浮点数。

 

### 五、实验步骤

#### 5.1 普通卷积计算算子

##### 5.1.1 导入参数

n：输入层的长度和宽度，深度默认为1；

m：卷积核的长度和宽度，深度默认为1；

tensor：7\*7\*1(16bits)的输入层像素；

kernel：3\*3\*1(16bits)的卷积核权值；

##### 5.1.2 分配内存空间

answer：为计算结果提供存储空间，大小为5\*5\*1(16bits)。

##### 5.1.3 卷积层运算

对于answer的每一位，在输入张量中提取对应位置的m\*m的矩阵，与卷积核做点乘运算。

结构：4个循环（2个循环遍历answer + 2个循环提取张量并作点乘）。

##### 5.1.4 输出结果到文件中

 

#### 5.2 二值卷积计算算子

##### 5.2.1 导入参数

n：输入层的长度和宽度；

m：卷积核的长度和宽度；

tensor：7\*7\*16(1bits)的输入层像素；

kernel：3\*3\*16(1bits)的卷积核权值；

注：在此处，为简化输入过程，将纵向16层01参数打包成一个16位的整数。

bcnt：<img src="{{site.url}}/img/2022-5-20-MIPS实现卷积核/clip_image045-165304861404723.gif" alt="img" style="zoom:50%;" />的运算结果。为减少计算过程中的运算时间，为此将该部分的结果通过预处理放置在内存当中。将16位的答案拆分成两个8位的答案，相加即是结果。

##### 5.2.2 分配内存空间

answer：为计算结果提供存储空间，大小为5\*5\*16(1bits)。

##### 5.2.3 卷积层运算

对于answer的每一位，在输入张量中提取对应位置的m\*m的矩阵，与卷积核做二值卷积运算。

结构：4个循环（2个循环遍历answer + 2个循环提取张量并作二值卷积运算）。

##### 5.2.4 输出结果到文件中

 

#### 5.3 偏置项、BN层整合

##### 5.3.1 导入参数

x1：二值卷积计算得到的结果

myu：x1矩阵的平均值

sig：x1矩阵的标准差

beta：训练参数

ita：训练参数

bias：偏置项

linda：权重

n：x1矩阵的长度和宽度，16层的深度打包成一层

5.3.2 分配空间

x4：为计算结果提供存储空间，大小为5\*5\*16(1bits)。

5.3.3 计算参数

通过推导的公式：

<img src="{{site.url}}/img/2022-5-20-MIPS实现卷积核/clip_image046-165304861404724.gif" alt="img" style="zoom:50%;" />

计算参数<img src="{{site.url}}/img/2022-5-20-MIPS实现卷积核/clip_image048-165304861404725.gif" alt="img" style="zoom:50%;" />。

##### 5.3.4 计算结果

通过得到的<img src="{{site.url}}/img/2022-5-20-MIPS实现卷积核/clip_image050-165304861404726.gif" alt="img" style="zoom:50%;" />，计算$x_4$的结果。

##### 5.3.5 输出结果到文件中。

 

#### 5.4 寄存器复用优化

##### 5.4.1 导入参数

n：输入层的长度和宽度；

m：卷积核的长度和宽度；

tensor：7\*7\*16(1bits)的输入层像素；

k11 - k33：卷积核的9个权值。

注：在此处，为简化输入过程，将纵向16层01参数打包成一个16位的整数。

bcnt：的运算结果。为减少计算过程中的运算时间，为此将该部分的结果通过预处理放置在内存当中。将16位的答案拆分成两个8位的答案，相加即是结果。

##### 5.4.2 分配内存空间

answer：为计算结果提供存储空间，大小为5\*5\*16(1bits)。

##### 5.4.3 卷积计算

a. 提取行首的6个元素进3\*3矩阵的后两列；

b. 将后两列的元素移动至前两列；

c. 从内存中加载新一列的元素；

d. 3\*3矩阵与卷积核做bcnt运算；

e. 列下标右移一位，重复bcd，直到行末；

f. 移动至下一行，从a操作开始重复。

##### 5.4.4 输出答案进文件。

 

### 六、实验代码及注释

#### 6.1 普通整数卷积计算算子

```
	.data
n:	.word	7
m:	.word	3
tensor:	.word	3 0 1 5 0 3 0
		2 6 2 4 3 0 3
		2 4 1 0 6 1 4
		3 0 1 5 0 3 0
		2 6 2 4 3 2 3
		2 4 1 0 6 2 1
		2 6 2 4 4 0 3
kernel:	.word	1 0 1
		2 0 2
		1 0 1
answer:	.space	100
#space:	.asciiz	" "
	.text

input:	la	$a0,n
	lw	$a0,0($a0)
	la	$a1,m
	lw	$a1,0($a1)
	la	$s0,tensor
	la	$s1,kernel
	la	$s2,answer
#a0 -> n , the size of the tensor , n\*n\*1
#a1 -> m , the size of the kernel , m\*m\*1
#s0 -> tensor
#s1 -> kernel
#s2 -> answer

main:	sub	$a2,$a0,$a1
	addi	$a2,$a2,1	#a2 is the size of the answer , we call L
	addi	$t0,$zero,0	#i=0
loop1:	addi	$t1,$zero,0	#j=0
loop2:	addi	$s4,$zero,0	#ans[i\*L+j]
	addi	$t2,$zero,0	#ai=0
loop3:	addi	$t3,$zero,0	#aj=0
loop4:	add	$t4,$t0,$t2
	mul	$t4,$t4,$a0
	add	$t4,$t4,$t1
	add	$t4,$t4,$t3	#the location in tensor , tensor[(i+ai)\*L+j+aj]
	mul	$t5,$t2,$a1
	add	$t5,$t5,$t3	#the location in kernel , kernel[ai\*m+aj]
	mul	$t4,$t4,4
	mul	$t5,$t5,4	#word is 4
	add	$t4,$s0,$t4	#the number address in tensor
	add	$t5,$s1,$t5	#the number address in kernel
	lw	$t6,0($t4)	#the number in tensor
	lw	$t7,0($t5)	#the number in kernel
	mul	$t8,$t6,$t7
	add	$s4,$s4,$t8
	addi	$t3,$t3,1	#aj++
	bne	$t3,$a1,loop4
	addi	$t2,$t2,1	#ai++
	bne	$t2,$a1,loop3
	mul	$t4,$t0,$a2
	add	$t4,$t4,$t1	#i\*L+j
	mul	$t4,$t4,4	#word is 4
	add	$t5,$s2,$t4	#ans[i\*L+j]
	sw	$s4,0($t5)
	addi	$t1,$t1,1	#j++
	bne	$t1,$a0,loop2
	addi	$t0,$t0,1	#i++
	bne	$t0,$a0,loop1
	
out:	la	$t2,answer
#t2 -> address in answer
	addi	$t0,$zero,0	#i=0
p1:	addi	$t1,$zero,0	#j=0
p2:	li	$v0,1		#print ans
	lw	$a0,0($t2)
	addi	$t2,$t2,4	#next address
	syscall
	li	$v0,11		#print " "
	addi	$a0,$zero,0x20
	syscall
	addi	$t1,$t1,1	#j++
	bne	$t1,$a2,p2
	li	$v0,11		#print endl
	addi	$a0,$zero,0x0a
	syscall
	addi	$t0,$t0,1	#i++
	bne	$t0,$a2,p1
	
fin:	li	$v0,10
	syscall

```

#### 6.2 二值卷积计算算子

```
	.data
n:	.word	7
m:	.word	3
tensor:	.half	3 0 1 5 0 3 0
				2 6 2 4 3 0 3
				2 4 1 0 6 1 4
				3 0 1 5 0 3 0
				2 6 2 4 3 2 3
				2 4 1 0 6 2 1
				2 6 2 4 4 0 3
kernel:	.half	1 0 1
				2 0 2
				1 0 1
bcnt:	.byte	8 6 6 4 6 4 4 2
                6 4 4 2 4 2 2 0
                6 4 4 2 4 2 2 0
                4 2 2 0 2 0 0 -2
                6 4 4 2 4 2 2 0
                4 2 2 0 2 0 0 -2
                4 2 2 0 2 0 0 -2
                2 0 0 -2 0 -2 -2 -4
                6 4 4 2 4 2 2 0
                4 2 2 0 2 0 0 -2
                4 2 2 0 2 0 0 -2
                2 0 0 -2 0 -2 -2 -4
                4 2 2 0 2 0 0 -2
                2 0 0 -2 0 -2 -2 -4
                2 0 0 -2 0 -2 -2 -4
                0 -2 -2 -4 -2 -4 -4 -6
                6 4 4 2 4 2 2 0
                4 2 2 0 2 0 0 -2
                4 2 2 0 2 0 0 -2
                2 0 0 -2 0 -2 -2 -4
                4 2 2 0 2 0 0 -2
                2 0 0 -2 0 -2 -2 -4
                2 0 0 -2 0 -2 -2 -4
                0 -2 -2 -4 -2 -4 -4 -6
                4 2 2 0 2 0 0 -2
                2 0 0 -2 0 -2 -2 -4
                2 0 0 -2 0 -2 -2 -4
                0 -2 -2 -4 -2 -4 -4 -6
                2 0 0 -2 0 -2 -2 -4
                0 -2 -2 -4 -2 -4 -4 -6
                0 -2 -2 -4 -2 -4 -4 -6
                -2 -4 -4 -6 -4 -6 -6 -8
answer:	.space	100
space:	.asciiz	" "
		.text

input:	la	$a0,n
		lw	$a0,0($a0)
		la	$a1,m
		lw	$a1,0($a1)
		la	$s0,tensor
		la	$s1,kernel
		la	$s2,answer
		la	$s3,bcnt
#a0 -> n , the size of the tensor , n\*n
#a1 -> m , the size of the kernel , m\*m
#s0 -> tensor
#s1 -> kernel
#s2 -> answer
#s3 -> 2BCNT()-N, which N=8

pre:	sub		$a2,$a0,$a1
		addi	$a2,$a2,1
#a1 -> n-m+1, the size of the answer
		mul	$a3,$a0,2
#a3 -> 2\*n, add a3 to be next row address

main:	move	$s4,$s0
		move	$s7,$s2
#s4 -> row index in tensor
#s7 -> index in answer

		addi	$t0,$zero,0
loop1:	addi	$t1,$zero,0
#t0, t1 -> answer[t0,t1]

loop2:	move	$s5,$s4
		move	$s6,$s1
		addi	$t8,$zero,0
#s5 -> current index in tensor
#s6 -> current index in kernel
#t8 -> number in answer[t0, t1]

		addi	$t2,$zero,0
loop3:	addi	$t3,$zero,0
#t2, t3 ->kernel[t2,t3]

loop4:	lh	$t4,0($s5)
		lh	$t5,0($s6)
		xor	$t6,$t4,$t5
#t4 -> number in tensor[t0+t2][t1+t3]
#t5 -> number in kernel[t2][t3]
#t6 -> t4 xor t5

		andi	$t9,$t6,255	#get low 8 bits
		add		$t7,$s3,$t9
		lb		$t7,0($t7)
		add		$t8,$t8,$t7	#add low 8 bits
		srl		$t6,$t6,8	#get high 8 bits in answer
		andi	$t6,$t6,255
		add		$t7,$s3,$t6
		lb		$t7,0($t7)
		add		$t8,$t8,$t7	#add high 8 bits in answer
		addi	$s5,$s5,2	#next index in tensor
		addi	$s6,$s6,2	#next index in kernel
		addi	$t3,$t3,1
		bne		$t3,$a1,loop4
		add		$s4,$s4,$a3	#next row index in tensor
		move	$s5,$s4		#updata current index in tensor
		addi	$t2,$t2,1
		bne		$t2,$a1,loop3
		sw		$t8,0($s7)	#store t8 in s7
		addi	$s7,$s7,4
		addi	$s0,$s0,2
		move	$s4,$s0
		addi	$t1,$t1,1
		bne		$t1,$a2,loop2
loop21:	addi	$s0,$s0,2
		addi	$s4,$s4,2
		addi	$t1,$t1,1
		bne		$t1,$a0,loop21
		addi	$t0,$t0,1
		bne		$t0,$a2,loop1

out:	move	$t2,$s2
#t2 -> address in answer
		addi	$t0,$zero,0	#i=0
p1:		addi	$t1,$zero,0	#j=0
p2:		li		$v0,1		#print ans
		lw		$a0,0($t2)
		addi	$t2,$t2,4	#next address
		syscall
		li		$v0,4		#print " "
		la		$a0,space
		syscall
		addi	$t1,$t1,1	#j++
		bne		$t1,$a2,p2
		li		$v0,11		#print endl
		addi	$a0,$zero,0x0a
		syscall
		addi	$t0,$t0,1	#i++
		bne		$t0,$a2,p1
	
fin:	li	$v0,10
		syscall

```

#### 6.3 整合

```
	.data
x1:	.half	132 122 128 124 120 
			124 118 124 120 124 
			120 114 120 118 118 
			132 122 128 122 122 
			114 112 120 118 124 
x4:		.space	50
myu:	.double	120.0
sig:	.double	5.0
beta:	.double	5.0
ita:	.double	5.0
bias:	.double	-5.0
linda:	.double 1.0
n:		.word	5
space:	.asciiz	" "
		.text

main:	la	$t0,myu
		l.d	$f0,0($t0)
		la	$t0,beta
		l.d	$f2,0($t0)
		la	$t0,sig
		l.d	$f4,0($t0)
		la	$t0,ita
		l.d	$f6,0($t0)
		la	$t0,bias
		l.d	$f8,0($t0)
		la	$t0,linda
		l.d	$f14,0($t0)
		la	$s6,x1
		la	$s7,x4
		la	$a0,n
		lw	$a0,0($a0)
#f0 -> myu
#f2 -> beta
#f4 -> sigema
#f6 -> ita
#f8 -> b (bias)
#f14 -> linda
#s6 -> x1
#s7 -> x4
#a0 -> n

		mul.d	$f12,$f2,$f4
		div.d	$f12,$f12,$f6
		sub.d	$f10,$f0,$f12
		sub.d	$f10,$f10,$f8
		div.d	$f10,$f10,$f14
#f10 -> yimicita -> (myu-(beta\*sigema/gama)-b)/linda
		ceil.w.d	$f16,$f10
		floor.w.d	$f18,$f10
		mfc1.d		$a1,$f16
		mfc1.d		$a2,$f18
#f16, a1 -> ceil of yimicita
#f18, a2 -> floor of yimicita
		ceil.w.d	$f20,$f6
		mfc1.d		$a3,$f20
#a3 -> ceil of ita
		ceil.w.d	$f22,$f2
		mfc1.d		$t9,$f22
#t9 -> ceil of beta
	
#t0 -> i, t1 -> j
#t2 -> current x1
#t3 -> current x4
		move	$t0,$zero
loop1:	move	$t1,$zero
loop2:	lh		$t2,0($s6)
		#
		slt		$t4,$a3,$zero 
		bne		$t4,1,j2
		
		#gama<0
		slt		$t5,$t2,$a1
		bne		$t5,$zero,j12
		move	$t3,$zero	#x1>=yimixita2,ita<0
		j		okay
j12:	addi	$t3,$zero,1	#x1<yimixita2,ita<0
		j		okay
		
		#ita>0
j2:		beq		$a3,$zero,j3
		slt		$t5,$t2,$a2
		bne		$t5,1,j22
		move	$t3,$zero	#x1<yimixita1,ita>0
		j		okay
j22:	addi	$t3,$zero,1	#x1>=yimixita1,ita>0
		j		okay
		#ita=0
		
j3:		slt		$t5,$t9,$zero
		beq		$t5,$zero,j32
		move	$t3,$zero	#ita=0,beta<0
		j		okay
j32:	addi	$t3,$zero,1	#ita=0,beta>0
		#
		
okay:	sh		$t3,0($s7)
		addi	$s6,$s6,2
		addi	$s7,$s7,2
		addi	$t1,$t1,1
		bne		$t1,$a0,loop2
		addi	$t0,$t0,1
		bne		$t0,$a0,loop1

out:	la		$t2,x4
		move	$a1,$a0
		
#t2 -> address in answer
		addi	$t0,$zero,0	#i=0
p1:		addi	$t1,$zero,0	#j=0
p2:		li		$v0,1		#print ans
		lh		$a0,0($t2)
		addi	$t2,$t2,2	#next address
		syscall
		li		$v0,4		#print " "
		la		$a0,space
		syscall
		addi	$t1,$t1,1	#j++
		bne		$t1,$a1,p2
		li		$v0,11		#print endl
		addi	$a0,$zero,0x0a
		syscall
		addi	$t0,$t0,1	#i++
		bne		$t0,$a1,p1
	
fin:	li	$v0,10
		syscall

```

#### 6.4 寄存器复用优化

```
	.data
n:	.word	7
m:	.word	3
tensor:	.half	3 0 1 5 0 3 0
				2 6 2 4 3 0 3
				2 4 1 0 6 1 4
				3 0 1 5 0 3 0
				2 6 2 4 3 2 3
				2 4 1 0 6 2 1
				2 6 2 4 4 0 3
k11:	.float	1
k12:	.float	0
k13:	.float	1
k21:	.float	2
k22:	.float	0
k23:	.float	2
k31:	.float	1
k32:	.float	0
k33:	.float	1
bcnt:	.byte	8 6 6 4 6 4 4 2
                6 4 4 2 4 2 2 0
                6 4 4 2 4 2 2 0
                4 2 2 0 2 0 0 -2
                6 4 4 2 4 2 2 0
                4 2 2 0 2 0 0 -2
                4 2 2 0 2 0 0 -2
                2 0 0 -2 0 -2 -2 -4
                6 4 4 2 4 2 2 0
                4 2 2 0 2 0 0 -2
                4 2 2 0 2 0 0 -2
                2 0 0 -2 0 -2 -2 -4
                4 2 2 0 2 0 0 -2
                2 0 0 -2 0 -2 -2 -4
                2 0 0 -2 0 -2 -2 -4
                0 -2 -2 -4 -2 -4 -4 -6
                6 4 4 2 4 2 2 0
                4 2 2 0 2 0 0 -2
                4 2 2 0 2 0 0 -2
                2 0 0 -2 0 -2 -2 -4
                4 2 2 0 2 0 0 -2
                2 0 0 -2 0 -2 -2 -4
                2 0 0 -2 0 -2 -2 -4
                0 -2 -2 -4 -2 -4 -4 -6
                4 2 2 0 2 0 0 -2
                2 0 0 -2 0 -2 -2 -4
                2 0 0 -2 0 -2 -2 -4
                0 -2 -2 -4 -2 -4 -4 -6
                2 0 0 -2 0 -2 -2 -4
                0 -2 -2 -4 -2 -4 -4 -6
                0 -2 -2 -4 -2 -4 -4 -6
                -2 -4 -4 -6 -4 -6 -6 -8
answer:	.space	100
space:	.asciiz	" "
	.text

input:	la	$a0,n
		lw	$a0,0($a0)
		la	$a1,m
		lw	$a1,0($a1)
		la	$s0,tensor
		la	$s1,answer
		la	$s2,bcnt
#a0 -> n , the size of the tensor , n\*n
#a1 -> m , the size of the kernel , m\*m
#s0 -> tensor
#s1 -> answer
#s2 -> 2BCNT()-N, which N=8
		l.s	$f2,k11
		l.s	$f4,k21
		l.s	$f6,k31
		l.s	$f8,k12
		l.s	$f10,k22
		l.s	$f12,k32
		l.s	$f14,k13
		l.s	$f16,k23
		l.s	$f18,k33
#f2-f18 -> kernel

pre:	sub		$a2,$a0,$a1
		addi	$a2,$a2,1
#a2 -> n-m+1, the size of the answer

main:	move	$s3,$zero	#i=0
#take first 6 tensor
loop1:	lh		$t4,0($s0)
		lh		$t5,14($s0)
		lh		$t6,28($s0)
		lh		$t7,2($s0)
		lh		$t8,16($s0)
		lh		$t9,30($s0)
		addi	$s0,$s0,4	#move to the third

		move	$s4,$zero	#j=0
#let the 4-9 to be 1-6
loop2:	move	$v1,$t4
		move	$t2,$t5
		move	$t3,$t6
		move	$t4,$t7
		move	$t5,$t8
		move	$t6,$t9
#get the new three
		lh		$t7,0($s0)
		lh		$t8,14($s0)
		lh		$t9,28($s0)
#calculate
		move	$v0,$zero
#[1,1]
		ceil.w.s	$f1,$f2
		mfc1	$t0,$f1
		xor	$s5,$t0,$v1	#s5 -> tensor xor kernel
		andi	$s6,$s5,255	#get low 8 bits
		add	$s7,$s2,$s6
		lb	$s7,0($s7)	#s7 -> the number in bcnt
		add	$v0,$v0,$s7	#add low 8 bits
		srl	$s5,$s5,8	#get high 8 bits in answer
		andi	$s5,$s5,255
		add	$s7,$s2,$s5
		lb	$s7,0($s7)
		add	$v0,$v0,$s7	#add high 8 bits in answer
#[2,1]
		ceil.w.s	$f1,$f4
		mfc1	$t0,$f1
		xor	$s5,$t0,$t2	#s5 -> tensor xor kernel
		andi	$s6,$s5,255	#get low 8 bits
		add	$s7,$s2,$s6
		lb	$s7,0($s7)	#s7 -> the number in bcnt
		add	$v0,$v0,$s7	#add low 8 bits
		srl	$s5,$s5,8	#get high 8 bits in answer
		andi	$s5,$s5,255
		add	$s7,$s2,$s5
		lb	$s7,0($s7)
		add	$v0,$v0,$s7	#add high 8 bits in answer
#[3,1]
		ceil.w.s	$f1,$f6
		mfc1	$t0,$f1
		xor	$s5,$t0,$t3	#s5 -> tensor xor kernel
		andi	$s6,$s5,255	#get low 8 bits
		add	$s7,$s2,$s6
		lb	$s7,0($s7)	#s7 -> the number in bcnt
		add	$v0,$v0,$s7	#add low 8 bits
		srl	$s5,$s5,8	#get high 8 bits in answer
		andi	$s5,$s5,255
		add	$s7,$s2,$s5
		lb	$s7,0($s7)
		add	$v0,$v0,$s7	#add high 8 bits in answer
#[1,2]
		ceil.w.s	$f1,$f8
		mfc1	$t0,$f1
		xor	$s5,$t0,$t4	#s5 -> tensor xor kernel
		andi	$s6,$s5,255	#get low 8 bits
		add	$s7,$s2,$s6
		lb	$s7,0($s7)	#s7 -> the number in bcnt
		add	$v0,$v0,$s7	#add low 8 bits
		srl	$s5,$s5,8	#get high 8 bits in answer
		andi	$s5,$s5,255
		add	$s7,$s2,$s5
		lb	$s7,0($s7)
		add	$v0,$v0,$s7	#add high 8 bits in answer
#[2,2]
		ceil.w.s	$f1,$f10
		mfc1	$t0,$f1
		xor	$s5,$t0,$t5	#s5 -> tensor xor kernel
		andi	$s6,$s5,255	#get low 8 bits
		add	$s7,$s2,$s6
		lb	$s7,0($s7)	#s7 -> the number in bcnt
		add	$v0,$v0,$s7	#add low 8 bits
		srl	$s5,$s5,8	#get high 8 bits in answer
		andi	$s5,$s5,255
		add	$s7,$s2,$s5
		lb	$s7,0($s7)
		add	$v0,$v0,$s7	#add high 8 bits in answer
#[2,3]
		ceil.w.s	$f1,$f12
		mfc1	$t0,$f1
		xor	$s5,$t0,$t6	#s5 -> tensor xor kernel
		andi	$s6,$s5,255	#get low 8 bits
		add	$s7,$s2,$s6
		lb	$s7,0($s7)	#s7 -> the number in bcnt
		add	$v0,$v0,$s7	#add low 8 bits
		srl	$s5,$s5,8	#get high 8 bits in answer
		andi	$s5,$s5,255
		add	$s7,$s2,$s5
		lb	$s7,0($s7)
		add	$v0,$v0,$s7	#add high 8 bits in answer
#[1,3]
		ceil.w.s	$f1,$f14
		mfc1	$t0,$f1
		xor	$s5,$t0,$t7	#s5 -> tensor xor kernel
		andi	$s6,$s5,255	#get low 8 bits
		add	$s7,$s2,$s6
		lb	$s7,0($s7)	#s7 -> the number in bcnt
		add	$v0,$v0,$s7	#add low 8 bits
		srl	$s5,$s5,8	#get high 8 bits in answer
		andi	$s5,$s5,255
		add	$s7,$s2,$s5
		lb	$s7,0($s7)
		add	$v0,$v0,$s7	#add high 8 bits in answer
#[2,3]
		ceil.w.s	$f1,$f16
		mfc1	$t0,$f1
		xor	$s5,$t0,$t8	#s5 -> tensor xor kernel
		andi	$s6,$s5,255	#get low 8 bits
		add	$s7,$s2,$s6
		lb	$s7,0($s7)	#s7 -> the number in bcnt
		add	$v0,$v0,$s7	#add low 8 bits
		srl	$s5,$s5,8	#get high 8 bits in answer
		andi	$s5,$s5,255
		add	$s7,$s2,$s5
		lb	$s7,0($s7)
		add	$v0,$v0,$s7	#add high 8 bits in answer
#[3,3]
		ceil.w.s	$f1,$f18
		mfc1	$t0,$f1
		xor	$s5,$t0,$t9	#s5 -> tensor xor kernel
		andi	$s6,$s5,255	#get low 8 bits
		add	$s7,$s2,$s6
		lb	$s7,0($s7)	#s7 -> the number in bcnt
		add	$v0,$v0,$s7	#add low 8 bits
		srl	$s5,$s5,8	#get high 8 bits in answer
		andi	$s5,$s5,255
		add	$s7,$s2,$s5
		lb	$s7,0($s7)
		add	$v0,$v0,$s7	#add high 8 bits in answer

		sw		$v0,0($s1)
		addi	$s1,$s1,4
		addi	$s0,$s0,2
		addi	$s4,$s4,1	#j++
		bne		$s4,$a2,loop2
		addi	$s3,$s3,1	#i++
		bne		$s3,$a2,loop1

out:	la		$t2,answer
#t2 -> address in answer
		addi	$t0,$zero,0	#i=0
p1:		addi	$t1,$zero,0	#j=0
p2:		li		$v0,1		#print ans
		lw		$a0,0($t2)
		addi	$t2,$t2,4	#next address
		syscall
		li		$v0,4		#print " "
		la		$a0,space
		syscall
		addi	$t1,$t1,1	#j++
		bne		$t1,$a2,p2
		li		$v0,11		#print endl
		addi	$a0,$zero,0x0a
		syscall
		addi	$t0,$t0,1	#i++
		bne		$t0,$a2,p1
	
fin:	li	$v0,10
		syscall
```



### 七、实验结果及分析

#### 7.1 普通卷积计算算子

##### 7.1.1 实验结果

<img src="{{site.url}}/img/2022-5-20-MIPS实现卷积核/clip_image054-165304861404728.gif" alt="1607306294(1)" style="zoom:50%;" /> =>  <img src="{{site.url}}/img/2022-5-20-MIPS实现卷积核/clip_image056-165304861404729.gif" alt="1607306258(1)" style="zoom:50%;" />

 

##### 7.1.2 结果分析

15=3\*1+0\*0+1\*1+2\*2+6\*0+2\*2+2\*1+4\*0+1\*1

29=0\*1+1\*0+5\*1+6\*2+2\*0+4\*2+4\*1+1\*0+0\*1

18=1\*1+5\*0+0\*1+2\*2+4\*0+3\*2+1\*1+0\*0+6\*1

17=5\*1+0\*0+3\*1+4\*2+3\*0+0\*2+0\*1+6\*0+1\*1

22=0\*1+3\*0+0\*1+3\*2+0\*0+3\*2+6\*1+1\*0+4\*1

14=2\*1+6\*0+2\*1+2\*2+4\*0+1\*2+3\*1+0\*0+1\*1

23=6\*1+2\*0+4\*1+4\*2+1\*0+0\*2+0\*1+1\*0+5\*1

20=2\*1+4\*0+3\*1+1\*2+0\*0+6\*2+1\*1+5\*0+0\*1

14=4\*1+3\*0+0\*1+0\*2+6\*0+1\*2+5\*1+0\*0+3\*1

26=3\*1+0\*0+3\*1+6\*2+1\*0+4\*2+0\*1+3\*0+0\*1

15=2\*1+4\*0+1\*1+3\*2+0\*0+1\*2+2\*1+6\*0+2\*1

24=4\*1+1\*0+0\*1+0\*2+1\*0+5\*2+6\*1+2\*0+4\*1

14=1\*1+0\*0+6\*1+1\*2+5\*0+0\*2+2\*1+4\*0+3\*1

23=0\*1+6\*0+1\*1+5\*2+0\*0+3\*2+4\*1+3\*0+2\*1

16=6\*1+1\*0+4\*1+0\*2+3\*0+0\*2+3\*1+2\*0+3\*1

15=3\*1+0\*0+1\*1+2\*2+6\*0+2\*2+2\*1+4\*0+1\*1

29=0\*1+1\*0+5\*1+6\*2+2\*0+4\*2+4\*1+1\*0+0\*1

18=1\*1+5\*0+0\*1+2\*2+4\*0+3\*2+1\*1+0\*0+6\*1

22=5\*1+0\*0+3\*1+4\*2+3\*0+2\*2+0\*1+6\*0+2\*1

19=0\*1+3\*0+0\*1+3\*2+2\*0+3\*2+6\*1+2\*0+1\*1

14=2\*1+6\*0+2\*1+2\*2+4\*0+1\*2+2\*1+6\*0+2\*1

28=6\*1+2\*0+4\*1+4\*2+1\*0+0\*2+6\*1+2\*0+4\*1

25=2\*1+4\*0+3\*1+1\*2+0\*0+6\*2+2\*1+4\*0+4\*1

14=4\*1+3\*0+2\*1+0\*2+6\*0+2\*2+4\*1+4\*0+0\*1

27=3\*1+2\*0+3\*1+6\*2+2\*0+1\*2+4\*1+0\*0+3\*1

 

#### 7.2 二值卷积计算算子

##### 7.2.1 实验结果

<img src="{{site.url}}/img/2022-5-20-MIPS实现卷积核/clip_image058-165304861404730.gif" alt="1607311976(1)" style="zoom:50%;" /> =>  <img src="{{site.url}}/img/2022-5-20-MIPS实现卷积核/clip_image060-165304861404731.gif" alt="1607311956(1)" style="zoom:50%;" />

##### 7.2.2 结果分析

经核实，结果正确。

 

#### 7.3 偏置项、BN层整合

##### 7.3.1 实验结果

<img src="{{site.url}}/img/2022-5-20-MIPS实现卷积核/clip_image062-165304861404732.gif" alt="1607354678(1)" style="zoom:50%;" />  =>  <img src="{{site.url}}/img/2022-5-20-MIPS实现卷积核/clip_image064-165304861404733.gif" alt="1607354553(1)" style="zoom:50%;" />

##### 7.3.2 结果分析

<img src="{{site.url}}/img/2022-5-20-MIPS实现卷积核/clip_image066-165304861404734.gif" alt="img" style="zoom:50%;" />

<img src="{{site.url}}/img/2022-5-20-MIPS实现卷积核/clip_image068-165304861404735.gif" alt="img" style="zoom:50%;" />

132>120=1

122>120=1

128>120=1

124>120=1

120=120=1

124>120=1

118<120=0

124>120=1

120=120=1

124>120=1

120=120=1

114<120=0

120=120=1

118<120=0

118<120=0

132>120=1

122>120=1

128>120=1

122>120=1

122>120=1

114<120=0

112<120=0

120=120=1

118<120=0

124>120=1

 

#### 7.4 寄存器复用优化

##### 7.4.1 实验结果

<img src="{{site.url}}/img/2022-5-20-MIPS实现卷积核/clip_image070-165304861404736.gif" alt="1607357715(1)" style="zoom:50%;" />

##### 7.4.2 结果分析

在实验二的基础上仅修改了寄存器复用优化功能，得到的结果相同，即实验正确。



### 八、参考文献

1. 论文 1：daBNN: A Super Fast Inference Framework for Binary Neural Networks on ARM devices，https://arxiv.org/abs/1908.05858
2. 论文 2: PhoneBit: Efficient GPU-Accelerated Binary Neural Network Inference Engine for Mobile Phones, https://ieeexplore.ieee.org/document/9116236（二值神经网络参考）